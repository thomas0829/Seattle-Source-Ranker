"""
Seattle Project Collector
Strategy: Find Seattle developers â†’ Sort by followers/repos â†’ Fetch their projects â†’ Collect 10,000
"""
import os
import json
import time
import requests
from typing import List, Dict, Set
from tqdm import tqdm
from datetime import datetime


class SeattleProjectCollector:
    """Collect projects from Seattle-area developers"""
    
    def __init__(self, token: str = None):
        self.token = token or os.getenv("GITHUB_TOKEN")
        if not self.token:
            raise ValueError("âŒ GitHub token required. Set GITHUB_TOKEN environment variable.")
        
        self.headers = {
            "Authorization": f"Bearer {self.token}",
            "Accept": "application/vnd.github.v3+json"
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def search_seattle_users(self, sort: str = "followers", max_users: int = 5000) -> List[Dict]:
        """
        Search for Seattle-area users
        
        Args:
            sort: Sort method (followers, repositories, joined)
            max_users: Maximum number of users to fetch
        """
        print(f"ğŸ” Searching for Seattle developers (sort: {sort})...")
        
        users = []
        page = 1
        per_page = 100
        
        # GitHub search API returns max 1000 results
        max_pages = min(10, (max_users + per_page - 1) // per_page)
        
        with tqdm(total=max_users, desc="Fetching users") as pbar:
            while page <= max_pages and len(users) < max_users:
                try:
                    url = f"https://api.github.com/search/users"
                    params = {
                        "q": "location:seattle",
                        "sort": sort,
                        "order": "desc",
                        "per_page": per_page,
                        "page": page
                    }
                    
                    response = self.session.get(url, params=params, timeout=30)
                    
                    if response.status_code == 403:
                        # Rate limit hit
                        reset_time = int(response.headers.get("X-RateLimit-Reset", 0))
                        if reset_time:
                            wait_time = reset_time - time.time() + 5
                            if wait_time > 0:
                                print(f"\nâ³ Rate limit é”åˆ°,ç­‰å¾… {int(wait_time)} ç§’...")
                                time.sleep(wait_time)
                                continue
                    
                    response.raise_for_status()
                    data = response.json()
                    
                    items = data.get("items", [])
                    if not items:
                        break
                    
                    users.extend(items)
                    pbar.update(len(items))
                    page += 1
                    
                    # é¿å…éå¿«è«‹æ±‚
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"\nâŒ Failed to fetch users (page {page}): {e}")
                    break
        
        print(f"âœ… Found {len(users)}  Seattle developers")
        return users[:max_users]
    
    def get_user_repositories(self, username: str) -> List[Dict]:
        """Get all public repositories for a user"""
        repos = []
        page = 1
        per_page = 100
        
        while True:
            try:
                url = f"https://api.github.com/users/{username}/repos"
                params = {
                    "sort": "updated",
                    "per_page": per_page,
                    "page": page
                }
                
                response = self.session.get(url, params=params, timeout=30)
                
                if response.status_code == 404:
                    # User does not exist or was deleted
                    break
                
                if response.status_code == 403:
                    # Rate limit
                    reset_time = int(response.headers.get("X-RateLimit-Reset", 0))
                    if reset_time:
                        wait_time = reset_time - time.time() + 5
                        if wait_time > 0:
                            time.sleep(wait_time)
                            continue
                
                response.raise_for_status()
                data = response.json()
                
                if not data:
                    break
                
                repos.extend(data)
                page += 1
                
                # é¿å…éå¿«è«‹æ±‚
                time.sleep(0.5)
                
            except Exception as e:
                print(f"\nâš ï¸  Fetching {username} 's repositories failed: {e}")
                break
        
        return repos
    
    def collect_projects(
        self,
        target_count: int = 10000,
        sort_users_by: str = "followers",
        output_file: str = "data/seattle_projects_10000.json"
    ) -> List[Dict]:
        """
        æ”¶é›†è¥¿é›…åœ–é–‹ç™¼è€…çš„å°ˆæ¡ˆ
        
        Args:
            target_count: targetå°ˆæ¡ˆæ•¸é‡
            sort_users_by: ç”¨æˆ¶æ’åºæ–¹å¼
            output_file: è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
        """
        print(f"\nğŸš€ Starting Seattle project collection (target: {target_count} )")
        print("="*60)
        
        # 1. Fetchingè¥¿é›…åœ–é–‹ç™¼è€…
        # ç‚ºäº†æ”¶é›† 10000 å°ˆæ¡ˆ,ä¼°è¨ˆéœ€è¦ 1000-2000 æ´»èºç”¨æˆ¶
        users = self.search_seattle_users(sort=sort_users_by, max_users=1000)
        
        if not users:
            print("âŒ æœªFoundè¥¿é›…åœ–é–‹ç™¼è€…")
            return []
        
        # 2. Collecting projects
        print(f"\nğŸ“¦ Starting project collection...")
        all_projects = []
        seen_repos = set()  # å»é‡(ç”¨ full_name)
        
        with tqdm(total=target_count, desc="Collecting projects") as pbar:
            for user in users:
                if len(all_projects) >= target_count:
                    break
                
                username = user["login"]
                
                # Fetchingç”¨æˆ¶çš„å€‰åº«
                repos = self.get_user_repositories(username)
                
                for repo in repos:
                    if len(all_projects) >= target_count:
                        break
                    
                    # å»é‡
                    repo_full_name = repo["full_name"]
                    if repo_full_name in seen_repos:
                        continue
                    
                    seen_repos.add(repo_full_name)
                    
                    # æå–éœ€è¦çš„ä¿¡æ¯
                    project = {
                        "name_with_owner": repo["full_name"],
                        "name": repo["name"],
                        "description": repo.get("description", ""),
                        "url": repo["html_url"],
                        "stars": repo["stargazers_count"],
                        "forks": repo["forks_count"],
                        "watchers": repo["watchers_count"],
                        "open_issues": repo["open_issues_count"],
                        "created_at": repo["created_at"],
                        "updated_at": repo["updated_at"],
                        "pushed_at": repo.get("pushed_at", ""),
                        "language": repo.get("language", ""),
                        "license": repo.get("license", {}).get("spdx_id", "") if repo.get("license") else "",
                        "owner": {
                            "login": user["login"],
                            "type": user["type"],
                            "avatar_url": user.get("avatar_url", ""),
                        },
                        "is_fork": repo["fork"],
                        "is_archived": repo.get("archived", False),
                    }
                    
                    all_projects.append(project)
                    pbar.update(1)
        
        print(f"\nâœ… Total collected {len(all_projects)} å°ˆæ¡ˆ")
        
        # 3. æŒ‰ stars æ’åº
        print(f"\nâ­ Sorting by stars...")
        all_projects.sort(key=lambda x: x["stars"], reverse=True)
        
        # 4. Statistics
        self._print_statistics(all_projects)
        
        # 5. ä¿å­˜æ•¸æ“š
        print(f"\nğŸ’¾ Saving data to: {output_file}")
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_projects, f, indent=2, ensure_ascii=False)
        
        # åŒæ™‚ä¿å­˜å…ƒæ•¸æ“š
        metadata = {
            "collection_time": datetime.now().isoformat(),
            "total_projects": len(all_projects),
            "total_users": len(users),
            "sort_users_by": sort_users_by,
            "target_count": target_count,
        }
        
        metadata_file = output_file.replace(".json", "_metadata.json")
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š Metadata saved to: {metadata_file}")
        print(f"\nâœ… Complete! Ready for analysis.")
        
        return all_projects
    
    def _print_statistics(self, projects: List[Dict]):
        """æ‰“å°Statistics"""
        print(f"\nğŸ“Š Statistics:")
        print(f"   Total projects: {len(projects)}")
        
        # Language distribution
        languages = {}
        for proj in projects:
            lang = proj.get("language") or "Unknown"
            languages[lang] = languages.get(lang, 0) + 1
        
        print(f"\nğŸ”¤ Language distribution (top 15):")
        sorted_langs = sorted(languages.items(), key=lambda x: x[1], reverse=True)
        for lang, count in sorted_langs[:15]:
            print(f"   {lang:20s}: {count:5d} å°ˆæ¡ˆ ({count/len(projects)*100:.1f}%)")
        
        # Star distribution
        star_ranges = {
            '10000+': 0,
            '5000-9999': 0,
            '1000-4999': 0,
            '500-999': 0,
            '100-499': 0,
            '50-99': 0,
            '10-49': 0,
            '1-9': 0,
            '0': 0
        }
        
        for proj in projects:
            stars = proj.get("stars", 0)
            if stars >= 10000:
                star_ranges['10000+'] += 1
            elif stars >= 5000:
                star_ranges['5000-9999'] += 1
            elif stars >= 1000:
                star_ranges['1000-4999'] += 1
            elif stars >= 500:
                star_ranges['500-999'] += 1
            elif stars >= 100:
                star_ranges['100-499'] += 1
            elif stars >= 50:
                star_ranges['50-99'] += 1
            elif stars >= 10:
                star_ranges['10-49'] += 1
            elif stars >= 1:
                star_ranges['1-9'] += 1
            else:
                star_ranges['0'] += 1
        
        print(f"\nâ­ Star distribution:")
        for range_name, count in star_ranges.items():
            if count > 0:
                print(f"   {range_name:15s}: {count:5d} å°ˆæ¡ˆ ({count/len(projects)*100:.1f}%)")
        
        # top 20 æœ€å—æ­¡è¿çš„å°ˆæ¡ˆ
        print(f"\nğŸ† top 20 æœ€å—æ­¡è¿çš„å°ˆæ¡ˆ:")
        for i, proj in enumerate(projects[:20], 1):
            print(f"   {i:2d}. {proj['name_with_owner']:50s} {proj['stars']:7d} â­ ({proj.get('language', 'N/A')})")


def main():
    """Main function"""
    collector = SeattleProjectCollector()
    
    # æ”¶é›† 10000 å°ˆæ¡ˆ
    projects = collector.collect_projects(
        target_count=10000,
        sort_users_by="followers",  # or "repositories"
        output_file="data/seattle_projects_10000.json"
    )
    
    print(f"\nâœ… Successfully collected {len(projects)} è¥¿é›…åœ–å°ˆæ¡ˆ!")


if __name__ == "__main__":
    main()
